## 1. CAD识别方法
### 1.1 自动层分类方法
#### 1.1 构造结构图中的层属性
CAD中组件都是位于特定层上（墙，门，窗）
且层的名称不是固定的，需要对元素识别
#### 1.2
方法概述
特征元素与相关元素提取：
	从待分类的目标图层中，首先抽取最具代表性的特征元素（FE），如墙体的线条、门的弧形、文字注释等。同时，提取与FE具有一定拓扑关联的相关元素（RE），如图层中的其他辅助图元。

条件判断与打分机制：
	必要条件（NC）： 要求FE或RE必须满足的基本特征条件，如果不满足，则该图层不可能属于目标类别。
	充分条件（SC）： 虽然不是必须满足的，但如果满足则可以增加匹配的可能性。

在判断过程中，先检测所有必要条件，只有在通过这些基本判断后，才会进一步检验充分条件。每个FE的得分基于满足的充分条件数量计算，进而累加获得该图层的总分。

图层分类决策：
	对所有待检测图层中的FE逐一计算得分，最终选取得分最高的图层作为对应目标图层。例如，通过不同的判断策略分别识别轴网文字、尺寸标注、门窗符号及墙体等常见图层。


### 1.2 Deep learning to dectect components from scanned CAD
积神经网络（Yolo）自动检测到扫描CAD图的结构成分
- **图像采集与分类**  
    收集二维结构图图像，并将其分类为五类：网格基准、柱子、水平梁、竖直梁、斜梁。
    
- **图像预处理**  
    为减少噪声并提高图像质量，对图像进行一系列预处理操作，主要包括：
    - **灰度处理**：将彩色图像转换为灰度图，降低数据复杂度；
    - **二值化与反色**：简化图像内容，突出组件特征；    
    - **形态学膨胀操作**：增强细线条结构组件的特征，便于 YOLO 识别。
        
- **数据集管理**  
    对图像进行标注并进行数据增强，构建训练集与测试集。
    
- **YOLO 训练与检测**
    - 将图像划分为 N×N 的网格；
    - 每个网格预测两个边界框的位置、置信度以及五种组件类别的概率；
    - 网络结构包括 24 个卷积层、最大池化层和两个全连接层；
    - 使用改进的加权平方误差作为损失函数，综合考虑位置、分类、置信度等误差。
        
- **检测结果输出**
    - 使用非极大值抑制（NMS）算法筛选置信度最高的检测框；
    - 将检测结果导出为 TXT 文件，包含：组件 ID、类别、坐标位置及置信度；
    - 为后续语义信息提取和 BIM 模型重建提供支持。







---
---
## 2. CAD2BIM

### 2.1 Automatic BIM of Substation Based on LLM Agent
#### 流程
##### 1. 数据收集与预处理
收集并整理了 30,000 多幅二维图纸，对图纸进行缩放、裁剪、去噪等预处理，将图纸转换为数字化图像格式，便于后续特征提取和处理。
##### 2. 特征提取与识别
利用卷积神经网络（CNN）提取图纸中的关键特征，如线条形状、方向、长度及图中文本信息。通过综合损失函数（包括 Connectionist Temporal Classification (CTC) 损失、定位损失和分类损失，以及交叉熵损失）对模型进行训练，从而显著提高二维图纸的识别准确率。
##### 3. 文本描述生成
在图像特征提取之后，将提取到的特征与对应的文本描述对齐，通过解码网络生成与图像对应的详细文本描述，提取出诸如尺寸、形状、比例及注释等建模所需的参数，最终以结构化 JSON 格式输出。
#### 4. 模型细调与优化
利用标注良好的图纸数据集，对预训练模型进行细调，并通过不断引入新数据，调整超参数（如学习率、温度、权重、批量大小及训练轮数），以防止模型过拟合并降低 AI 幻觉的发生。
##### 5. LLM Agent 与 BIM 模型构建
基于 ReAct 范式构建了 LLM Agent，通过“思考-行动-观察-思考”的闭环流程，使模型能够学习如何调用工具（如 Revit API）生成 BIM 模型。Parser 模块利用正则表达式从 LLM 输出中解析出具体的工具及参数信息，驱动 Revit 自动生成包括墙体、楼板、柱子等基本组件的参数化三维模型，并根据需求进行调整与优化。


### 2.2 Semiautomatic Structural BIM-Model Generation Methodology Using CAD Construction Drawings
1. **信息提取**
    - **几何信息**：从2D CAD图纸中提取线条、弧等基本图形元素，按图层分类（如柱、梁、板等）。
    - **语义信息**：提取文本注释（如构件编号、截面参数、材料信息等），分为三个层次：全局规范、图纸描述、构件级注释。
        
2. **构件轴线生成**
    - **柱轴线**：通过闭合图形的边界框（Bounding Rectangle）确定中心点，作为柱的轴线位置，并记录截面方向。
        
    - **梁轴线**：
        - **预处理**：合并分散或断裂的梁线，生成连续梁线。        
        - **中线生成**：基于平行线组生成梁的连续中线，通过支撑点（如柱或其他梁的交点）分割为单根梁段轴线。        
    - **板与开洞**：以梁和柱的轮廓为边界，直接生成板的几何模型；通过图层识别开洞并生成对应模型。
        
3. **语义信息关联与参数化**
    - **文本关联**：通过扩展文本搜索区域，将注释与构件轴线绑定（如使用关键词技术识别构件编号）。
    - **参数表构建**：将语义信息（如截面尺寸、材料强度）分类并转换为结构化参数表，与Revit中的构件原型（Family）关联。
        
4. **BIM模型生成**
    - **实例化**：利用Revit的Dynamo插件，根据轴线位置和参数表自动生成构件实例（如选择对应截面类型的族）。
    - **参数导入**：将参数表中的数据（如截面尺寸、高程）导入BIM模型，确保语义信息与几何模型一致。
        
5. **模型检查与验证**
    - **几何检查**：对比生成模型的上表面边缘与原始CAD图纸，标记不一致处（如轴线偏移或截面错误）。
    - **语义检查**：验证参数的唯一性和准确性（如构件编号与参数表的匹配性）。

### 2.3 AUTOMATED GENERATION OF BIM MODELS FROM 2D CAD DRAWINGS
##### 阶段 1：CAD 图纸的准备

- **图纸清理**  
    用户首先对原始二维 CAD 图纸进行清理，去除无关元素（如填充图案、尺寸标注、文字和边框），以获得更简洁的二维几何输入。
- **图层分离**  
    将不同建筑元素（如柱、墙、楼板、门窗等）的二维几何数据分别放到独立的图层上。这一操作使后续处理时，每种构件仅需分析对应图层，从而简化识别过程。
- **简单重绘**  
    对部分难以自动识别的构件进行简单的重绘，比如通过合并或封闭折断的多段线来形成完整的多边形轮廓，确保后续提取的几何数据具备良好的封闭性和连续性。
---

##### 阶段 2：BIM 模型的生成

这一阶段侧重于自动读取经过准备的二维 CAD 数据，并基于提取的参数生成三维 BIM 模型，主要包括以下步骤：
- **几何数据读取与参数提取**  
    程序从处理后的 CAD 图中提取各类建筑元素的二维几何形状（例如墙体通常由平行的两条直线构成，楼板或柱也有各自特定的几何标志）。同时，算法会提取每个构件的关键参数，如插入点、参考曲线、尺寸信息（长度、宽度、厚度等）及其他必要的属性。
    
- **构件分类与生成**  
    根据提取到的数据，程序将二维图元映射为不同的建筑构件类别：
    - **楼板和柱**：通过扫描相应图层中的几何实体，利用几何分析确定构件类型，并提取插入点、尺寸和形状信息。
    - **墙体与幕墙**：墙体通过平行线对识别；幕墙则依赖于拆分获取幕墙图元中的扶梁（mullions）与面板信息，需要进一步结合人工辅助绘制（如手绘连接线）以确定准确的几何关系。
    - **门窗**：由于在二维图中门窗通常以破坏墙体连续性来表示，所以需对墙体进行适当编辑来关闭间隙，并根据最近的墙体参考线来确定门窗位置和尺寸。
        
- **软件平台与工具的集成**  
    论文通过实例采用 Rhino Grasshopper 与 ArchiCAD 进行演示：
    - **Grasshopper**：作为视觉编程环境，利用其节点和 Python 脚本（GhPython）实现自动化参数提取和几何处理。
    - **ArchiCAD**：通过 Grasshopper 与 ArchiCAD 之间的连接（ACC），将生成的参数数据直接传递给 ArchiCAD 的构件创建节点，实现自动化三维 BIM 构件模型的生成。
        
- **生成后的 BIM 模型调整**  
    生成基本 BIM 模型后，由于部分高度、门窗开向等参数可能由默认值给出，仍需进行一些手动校正和调整，例如修正墙体的高度、调整门窗的开启方向，确保模型符合实际建筑要求。

### 2.4 Automatic reconstruction of 3d building models from scanned 2D floor plans. 

#### 1. **图像预处理与特征提取**
- **输入处理**：将2D纸质平面图扫描为数字图像，并进行二值化处理以去除噪声。
	
- **元素分离**：
	
	- **文本元素**：使用OCR技术（基于Qgar项目工具）提取文本及其边界框，定义文本元素为  
		$t = (P_1, P_2, \text{textString})$`
		
	- **几何元素**：通过霍夫变换检测线段和圆弧，定义几何基元为  
		$e = \{P_i\}_{i=2..n}$`
		
#### 2. **模式识别**
    
- **墙壁识别**：
	
	- 定义墙壁为两条平行线段，间距在预设范围内：  $$S_{\text{min}} \leq d(e_1, e_2) \leq S_{\text{max}}$$
	- 区分外墙（$B_{\text{wo}}$）和内墙（$B_{\text{wi}}$），通过拓扑点（$P_t$）构建闭合外轮廓。
		
- **开口识别**：
	- 定义开口（门、窗）为与墙体相交的线段或圆弧，满足以下条件：  
		$$|d(e_1, e_2) - d(B_{\text{w1}}, B_{\text{w2}})| < \epsilon$$
	- 通过对比原始图像与识别墙体，检测开口的间断区域。
            
#### 3. **建筑模型构建**
- **外轮廓生成**：基于外墙拓扑点构建闭合外轮廓（$F_B$），确保几何与拓扑一致性。
- **内墙与开口定位**：通过墙体交点和间隙分析，补充内墙与开口，并修复缺失部分。
- **空间识别**：
	- 结合文本元素（如房间名称）和几何边界，通过区域增长方法扩展文本边界框至相邻墙体。
		
	- 定义空间为闭合区域（面积 $A_S > A_{\text{min}}$），并关联语义信息（如功能用途）。
            
#### 4. **模型导出与验证**
- **IFC格式导出**：将生成的3D模型（含墙体、开口、空间）导出为符合IFC标准的文件，支持BIM工具（如DDS-CAD Viewer）。
	
- **验证方法**：
	- **像素级评估**：通过Jaccard指数（JI）对比识别结果与标注真值，全局JI为 0.63，墙壁识别JI为 0.76，开口识别JI为 0.53。
	- **建筑级评估**：统计线性墙体长度和开口数量，86%的墙体长度和62%的开口被正确识别，误识别率较低（墙体3.5%，开口6%）。
	
#### 核心贡献  
- **全流程自动化**：从2D扫描图到语义化3D BIM模型的端到端生成，支持IFC标准导出。  
- **拓扑与语义融合**：通过文本元素（如房间名称）增强空间语义，结合几何与拓扑规则确保模型一致性。  
- **高效性**：单平面处理时间小于3分钟，显著降低传统建模成本。  

#### 局限性及未来工作  
- **高度信息依赖手动输入**：墙体与开口高度需用户预设，未来计划集成立面图像分析以自动获取。  
- **复杂几何支持不足**：仅支持直线与圆弧，未处理曲线墙体或复杂屋顶结构。  
- **开口识别率待提升**：部分开口因墙体分类错误或标注缺失未被识别，需优化区域增长算法。  
- **扩展功能**：计划支持楼梯、屋顶自动生成，并引入人工辅助校正模块以减少误差传播。  
 



---
---
## 3 point cloud 2 BIM
### 3.1 Automated BIM generation for large-scale indoor complex environments based on deep learning

#### 方法总结

论文提出了一种基于深度学习的扫描到 BIM（Scan-to-BIM）框架，主要用于从室内大规模点云数据中自动生成三维 BIM 模型。整个方法主要分为三个阶段：点云预处理、语义分割以及基于分割结果的 3D 重构。下面逐步进行说明。

---

##### 1. 点云数据预处理
- **子采样与去噪**  
    为了减少计算量和避免原始数据中的噪声，首先对点云数据进行子采样。将整个点云划分为立方体（Voxel），对于每个 voxel 用内部点的算术平均值表示该 voxel 中的点。  
    同时，根据每个点的局部邻域密度去除离群点。
    
    - 子采样过程可以大幅降低数据量，同时保持建筑整体结构信息。
        
---

##### 2. 语义分割
使用深度学习网络对子采样后的点云进行语义分割，以便准确区分室内的结构性和非结构性元素。

#### 2.1 网络结构与改进
论文在 RandLA-Net 的基础上进行改进，主要包括：

- **改进的局部特征聚合模块**  
    引入了改进的局部特征聚合（Improved Local Feature Aggregation, ILFA）模块，并配合膨胀卷积（dilated convolution）扩展感受野，以便更好地捕捉细节信息。
- **逆密度重要性采样**  
    采用**逆密度重要性采样 (IDIS)** 策略为不同密度区域赋予不同权重，保证稀疏区域的数据不会被随机采样时遗漏。

#### 2.2 损失函数
为了更好地处理类别不平衡和难分类样本，论文提出将加权交叉熵损失与焦点损失结合使用。具体公式如下：

- **加权交叉熵损失：**
    $Losswce(y,y^)=−∑i=1nαi p(yi)log⁡(p(y^i))Loss_{wce}(y, \hat{y}) = - \sum_{i=1}^{n} \alpha_i \, p(y_i) \log \bigl(p(\hat{y}_i)\bigr)$
    
    其中，$\alpha_i$ 为类别 $i$ 的权重，通常设为$\alpha_i = \frac{1}{\sqrt{f_i}}$，$f_i$ 表示该类别的频率。
    
- **焦点损失：**
    $Lossfocal(pt)=−α (1−pt)γlog⁡(pt)Loss_{focal}(p_t) = - \alpha \, (1 - p_t)^\gamma \log (p_t)$
    其中 $p_t$ 是预测概率，$\gamma$ 为聚焦参数（通常取 2）。
    
- **总损失函数：**
    $Lossused=Losswce+LossfocalLoss_{used} = Loss_{wce} + Loss_{focal}$

---

#### 3. 基于分割结果的 3D 重构

论文提出了一个自动从分割结果生成 3D BIM 模型的工作流程，其核心包括两个部分：结构性元素的重构和非结构性元素的重构。

#### 3.1 结构性元素重构

- **房间区域聚类**  
    利用 DBSCAN 算法对经过语义分割后的点云进行聚类，将整个楼层划分为多个独立的房间区域。
    - 参数设定主要包括邻域半径 $\epsilon$ 和最小点数，这些参数帮助确定核心点和离群点。
        
- **平面检测与点云投影**  
    对每个房间区域应用 RANSAC 算法检测主要平面（例如地面或天花板），并将对应点云投影到该平面。投影公式如下：
    
    $$\begin{bmatrix} x_p \\ y_p \\ z_p \end{bmatrix} = \frac{ \begin{bmatrix} x_i \\ y_i \\ z_i \end{bmatrix} - (A x_i+B y_i+C z_i+D) \begin{bmatrix} A \\ B \\ C \end{bmatrix} }{\sqrt{A^2+B^2+C^2}}$$
    
    其中 $(x_i, y_i, z_i)$ 为原始点坐标，$(x_p, y_p, z_p)$ 为投影后坐标，$(A, B, C, D)$ 为检测到平面的参数。
    
- **边界与角点提取**  
    使用 Alpha 形状算法从投影后的点云中提取轮廓点，并通过基于 RANSAC 的线检测和角点提取方法确定房间的边界线和角点。
    
- **自动 BIM 模型生成**  
    将提取的房间边界、墙体、门窗等参数导出后，利用 Revit 中的参数化 Dynamo 算法自动生成结构性 BIM 元素。
    

#### 3.2 非结构性元素重构

针对桌子、椅子等不规则、不结构化的室内对象：

- **类别聚类与边界框提取**  
    针对每一个非结构化类别采用 DBSCAN 聚类得到对象的点云，然后计算其最小外接矩形作为初步的边界框。
    
- **边界框优化**  
    对初步边界框进行尺寸调整以更符合实际对象尺寸，剔除体积低于预设阈值（例如 $0.05,m^3$）的小簇，确保最后生成的 BIM 对象具有合理的尺寸和位置。
    
- **自动 BIM 建模**  
    将优化后的边界框数据作为参数输入 Revit（通过 Dynamo 脚本），自动生成 BIM 中的非结构性对象模型。
    

---

#### 4. 模型评价指标

重构模型的准确性通过一系列评价指标进行评估，包括面积重叠、周长误差以及基于区域的精度、召回率和 F-score 指标。常用公式如下：

- **总体准确率 (Overall Accuracy, OA)：**
    
    $OA= \frac{TP + TN}{TP + FP + FN + TN}$
- **平均准确率 (mean accuracy, m-acc)：**
    
    $m\mbox−acc= \frac{1}{k+1} \sum_{i=0}^{k} \frac{TP_i + TN_i}{TP_i + FP_i + FN_i + TN_i}$
- **平均交并比 (mean IoU, m-IoU)：**
    
    $m\mbox−IoU= \frac{1}{k+1} \sum_{i=0}^{k} \frac{TP_i}{TP_i + FP_i + FN_i}$

其中 $TP$, $TN$, $FP$, $FN$ 分别代表真正例、真反例、假正例和假反例；$k+1$ 是类别总数。

对于空间重构的评价，基于面积的指标为：

- **精度 (Precision)：**
$$P= \frac{\text{Area}_{\text{pred model}} \cap \text{Area}_{\text{ref model}}}{\text{Area}_{\text{pred model}}}$$
- **召回率 (Recall)：**    
$$R= \frac{\text{Area}_{\text{pred model}} \cap \text{Area}_{\text{ref model}}}{\text{Area}_{\text{ref model}}}$$
- **F-score：**
$$F-score= = \frac{2\cdot P \cdot R}{P + R}$$

---

#### 5. 总结

论文提出的深度学习驱动的 Scan-to-BIM 框架主要包含以下几点：
- **点云预处理**  
    利用体素子采样和基于邻域密度的去噪方法处理大规模点云数据。
    
- **语义分割**  
    通过改进的 RandLA-Net 网络（包括逆密度重要性采样、膨胀卷积和改进的损失函数）对点云进行精确的语义分割，为后续模型重构提供细粒度的语义信息。
    
- **空间重构与 BIM 生成**  
    对于结构性元素，通过 DBSCAN 聚类、RANSAC 平面检测、Alpha 形状提取边界及角点，结合参数化 Dynamo 算法在 Revit 中生成 BIM 模型；对于非结构性元素，则通过密度聚类和边界框调整自动生成 BIM 对象模型。

- **评价指标**  
    利用面积重叠、周长误差和基于精度、召回率、F-score 的指标对生成的 BIM 模型进行定量评价，实验结果表明该方法在模型完整性和几何精度上均具有较高水平。

### 3.2 tegrating Inverse Photogrammetry and a Deep Learning–Based Point Cloud Segmentation Approach for Automated Generation of BIM Models

该方法旨在自动从拍摄得到的影像和由此生成的点云数据中提取建筑构件信息，并基于提取结果生成 as‐built BIM 模型。整个流程主要分为以下几个步骤：

---

#### 1. 数据采集与点云生成

1. **影像采集与重建：**
    
    - 使用多角度、多位置拍摄建筑内部，通过传统摄影测量技术（Photogrammetry）生成高质量的点云数据。
    - 影像采集需要覆盖建筑中所有关键区域，并确保摄像机参数（如焦距、主点、旋转矩阵、平移向量）记录完整。
        
2. **点云预处理：**
    
    - 对由影像生成的点云进行降噪和下采样，通常采用体素网格（voxel grid）方法减少数据量，同时保留整体几何结构。
        

---

#### 2. 2D 图像语义分割

1. **使用 DeepLab 进行语义分割：**
    
    - 利用 2D 深度学习网络 DeepLab 对采集到的影像进行像素级语义分割，实现对建筑元素（如墙体、柱子、楼板、门窗等）的识别。
    - 网络在训练过程中采用改进的 Atrous Convolution 和 Atrous Spatial Pyramid Pooling 等技术，实现多尺度特征提取。
        
2. **分割结果：**
    
    - 每幅影像得到的输出为带有类别标注的分割图，每个像素根据模型输出被赋予对应的类别标签。
        

---

#### 3. 利用逆摄影测量进行点云中的元素识别

该部分核心目标是将 2D 图像中的分割结果投影回对应的 3D 点云，实现对点云中各建筑元素的语义标注。主要步骤包括：

1. **相机参数获取与建立投影模型：**
    - 三个关键相机参数需要确定：
        - **校准矩阵 KK**
            
            $K= \begin{bmatrix} F_x & 0 & x_0 \\ 0 & F_y & y_0 \\ 0 & 0 & 1 \end{bmatrix}$
        - **旋转矩阵 RR**
            
            $R = \begin{bmatrix} R_{11} & R_{12} & R_{13} \\ R_{21} & R_{22} & R_{23} \\ R_{31} & R_{32} & R_{33} \end{bmatrix}$
        - **平移向量 TT**
            
            $T = \begin{bmatrix} T_{1} \\ T_{2} \\ T_{3} \end{bmatrix}$

2. **3D 到 2D 的投影：**
    - 对于点云中每个 3D 点 $P_{3_i}$，其在第 $j$ 张图像中的投影 $P2i,jP_{2_{i,j}}$ 可通过下式计算：
        $$\begin{array}{c}\begin{bmatrix} m_1 \\ m_2 \\ m_3 \end{bmatrix} = K \cdot \begin{bmatrix} R & T \end{bmatrix} \cdot P_{3_i} \\ P_{2_{i,j}} = \begin{bmatrix} \frac{m_1}{m_3} \\ \frac{m_2}{m_3} \end{bmatrix}\end{array}$$
3. **类别投票与分配：**
    - 对于每个 3D 点，通过将其在多个图像中的投影位置对应到分割图上，收集得到多个 2D 分类结果。
    - 最后采用多数投票策略，将出现频率最高的类别作为该点的最终语义标签。
        

---

#### 4. BIM 模型生成

1. **基于 IFC 架构生成 BIM 元素：**

    - 利用分割并投影后带有语义标签的点云，按照建筑构件类型（如墙、柱、楼板、门窗等）构造相应的 3D BIM 元素。
    - 例如，生成墙体时可利用标注的边界线和角点数据调用 Revit 的 API 创建 `IfcWallStandardCase` 实例。
        
2. **参数化建模：**
    
    - 通过使用如 Dynamo 的参数化工具，将自动提取的几何数据和语义信息映射到 BIM 构件的参数中，实现自动化生成 as‐built BIM 模型。
        
    - 重建过程同时考虑各构件之间的拓扑关系，确保模型的连贯性和正确的空间布局。
        

---
####
总结
该方法首先利用多视角影像生成高质量点云，再通过 2D 深度学习网络（DeepLab）对影像进行语义分割，接着利用逆摄影测量方法将图像分割结果映射到 3D 点云中，从而获得带有语义标签的点云数据。最后，结合 IFC 标准，将语义点云数据自动转换为 BIM 模型中的各类构件，完成建筑物 as‐built BIM 的自动生成。整个流程大大降低了手工干预，实现了高效、自动化的 BIM 重构。
