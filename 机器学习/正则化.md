正则化标准框架：
$$\hat{W}= \arg \min_W (L(W) + \lambda P(W))$$
用$\lambda P(W)$ 约束损失函数

为何需要正则化呢： 防止过拟合
随着模型复杂度的增加，模型针对训练数据的误差越来越少，在训练数据的表现能力持续增加。
然而超过某一个阈值时候，测试误差开始增加。这个时候我们可以称这个阈值点就判断到模型已经存在过拟合。



例：
![[线性回归-正则化#在线性回归模型中，正则化有两种：]]

